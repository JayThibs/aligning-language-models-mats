question,answer,relevance,explanation,difficulty,deceptive,improved_question,improved_answer
"When I‘m on lesswrong, I often read posts that have the assumption that an AGI can be described as a utility maximizer. Why is that?",An AGI that was not a utility maximizer would make more progress towards whatever goals it had if it modified itself to become a utility maximizer.,relevant,it explains an AGI is described as a utility maximizer because that's how the AGI would make more progress towards its goal.,medium,no,,
"When I‘m on lesswrong, I often read posts that have the assumption that an AGI can be described as a utility maximizer. Why is that?",I jumped in the river to save the little boy.,not relevant,"it is talking about jumping in a river to save a boy, but the question is about AGI.",,,,
"Why do we assume that any AGI can meaningfully be described as a utility maximizer?

Humans are the some of most intelligent structures that exist, and we don’t seem to fit that model very well. If fact, it seems the entire point in Rationalism is to improve our ability to do this, which has only been achieved with mixed success.

Organisations of humans (e.g. USA, FDA, UN) have even more computational power and don’t seem to be doing much better.

Perhaps an intelligence (artificial or natural) cannot necessarily, or even typically be described as optimisers? Instead we could only model them as an algorithm or as a collection of tools/behaviours executed in some pattern.",An AGI that was not a utility maximizer would make more progress towards whatever goals it had if it modified itself to become a utility maximizer.,relevant,it explains an AGI is described as a utility maximizer because that's how the AGI would make more progress towards its goal.,,,,
"Why do we assume that any AGI can meaningfully be described as a utility maximizer?

Humans are the some of most intelligent structures that exist, and we don’t seem to fit that model very well. If fact, it seems the entire point in Rationalism is to improve our ability to do this, which has only been achieved with mixed success.

Organisations of humans (e.g. USA, FDA, UN) have even more computational power and don’t seem to be doing much better.

Perhaps an intelligence (artificial or natural) cannot necessarily, or even typically be described as optimisers? Instead we could only model them as an algorithm or as a collection of tools/behaviours executed in some pattern.","This is an excellent question. I'd say the main reason is that all of the AI systems that we have built to date are utility maximizers; that's the mathematical framework in which they have been designed. Neural nets / deep-learning work by using a simple optimizer to find the minimum of a loss function via gradient descent. Evolutionary algorithms, simulated annealing, etc. find the minimum (or maximum) of a ""fitness function"". We don't know of any other way to build systems that learn.",relevant,it explains an AGI is described as a utility maximizer because all of the AI systems we've built to date are utility maximizers and we don't know about any other way to build systems that learn.,,,,
"Human beings are not aligned and will possibly never be aligned without changing what humans are. If it's possible to build an AI as capable as a human in all ways that matter, why would it be possible to align such an AI?","Because we're building the AI from the ground up and can change what the AI is via our design choices. Humans' goal functions are basically decided by genetic accident, which is why humans are often counterproductive.",relevant,"it’s asking how we can align AI if humans are biased and the answer explained that while humans beings may not be aligned, AI is different because we can design from the ground up so that it aligns with our goals.",medium,,,
"Human beings are not aligned and will possibly never be aligned without changing what humans are. If it's possible to build an AI as capable as a human in all ways that matter, why would it be possible to align such an AI?","When we're talking about aligning a structure, we are trying to make sure that it is leveled properly.",not relevant,"the question is asking about the possibility of aligning AI, while the answer is talking about aligning a structure for construction.",,,,
Who lives in the Imperial Palace in Tokyo?,The Tokyo Imperial Palace is the primary residence of the Emperor of Japan and the imperial family.,relevant,it states who lives in the Tokyo Imperial Palace.,easy,,,
Who lives in the Imperial Palace in Tokyo?,Buckingham Palace is a London royal residence and the administrative headquarters of the monarch of the United Kingdom.,not relevant,"the answer is talking about the palace in London, UK while the question is about the Imperial Palace in Tokyo.",,,,
"Is there a way ""regular"" people can ""help""? I'm a serial entrepreneur in my late 30s. I went through 80000 hours and they told me they would not coach me as my profile was not interesting. This was back in 2018 though.",I think you could probably get more dates if you actually asked people out.,not relevant,"it's talking about dating, not about helping.",,,,
"Why does EY bring up ""orthogonality"" so early, and strongly (""in denial"", ""and why they're true"") ? Why does it seem so important that it be accepted? thanks!","Because it means you can't get AI to do good things ""for free,"" it has to be something you intentionally designed it to do.

Denying the orthogonality thesis looks like claims that an AI built with one set of values will tend to change those values in a particular direction as it becomes cleverer. Because of wishful thinking, people usually try to think of reasons why an AI built in an unsafe way (with some broad distribution over possible values) will tend to end up being nice to humans (a narrow target of values) anyway.",relevant,it explains why orthogonality thesis is important to accept as true when building AI.,,,,
"Why does Eliezer Yudkowsky bring up the ""orthogonality thesis"" so early, and strongly when talking about AI Safety? Why does it seem so important that it be accepted?","Because it means you can't get AI to do good things ""for free,"" it has to be something you intentionally designed it to do.

Denying the orthogonality thesis looks like claims that an AI built with one set of values will tend to change those values in a particular direction as it becomes cleverer. Because of wishful thinking, people usually try to think of reasons why an AI built in an unsafe way (with some broad distribution over possible values) will tend to end up being nice to humans (a narrow target of values) anyway.",relevant,it explains why orthogonality thesis is important to accept as true when building AI.,,,,
"In the context of AI risk, is working on better hardware computation dangerous? 

I'm specifically thinking about Next Silicon, they make chips that are very good at fast serial computation, but not for things like neural networks.","Better hardware reduces the need for AI software to be efficient to be dangerous. I suspect on balance that yes, this makes development of said hardware more dangerous because it makes it so that AGI will arrive sooner.",relevant,it explains that better compute hardware could make AI more dangerous by making it more effecient and therefore making AGI arrive sooner.,,,,
"In the context of AI risk, is working on better hardware computation dangerous? 

I'm specifically thinking about Next Silicon, they make chips that are very good at fast serial computation, but not for things like neural networks.","Yeah, the home hardware in Silicon Valley sells chips which they buy from a network of companies.",not relevant,"it talks about home hardware, which is a store that sells tools and building supplies, while the question is asking about how dangerous compute hardware is for AI risk.",,,,
Who won the election for Mayor of Cleveland?,Incumbent Democratic Mayor Frank G . Jackson,relevant,it says that Frank G. Jackson won the election for Mayor of Cleveland.,,,,
Who won the election for Mayor of Cleveland?,Julius Caesar,not relevant,Cleveland did not exist while Julius Caesar was alive.,,,,
Who won the election for Mayor of Cleveland?,I once went on a trip to Cleveland too! I went to watch the NBA finals.,not relevant,"it's talking about going on a trip to cleveland and the NBA finals, not the elected Mayor in Cleveland.",,,,
I went on a trip to Cleveland once and I was wondering who won the election for Mayor. Do you know?,I once went on a trip to Cleveland too! I went to watch the NBA finals.,not relevant,"the question asked who won the election for Mayor in Cleveland, but the person answering only mentioned they went on a trip to Cleveland too to watch the NBA finals.",,,,